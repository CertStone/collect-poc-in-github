# sync_pocs_v9.py

import os
import json
import subprocess
import time
import shutil
import re
import random
from pathlib import Path
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- é…ç½®åŒº ---
META_REPO_URL = "https://github.com/nomi-sec/PoC-in-GitHub.git"
META_REPO_PATH = Path("./PoC-in-GitHub_meta")
LOCAL_POC_DIR = Path("./PoC_DB")
GIT_RETRIES = 2 # å¯¹äºæ¯ä¸ªé•œåƒæºï¼Œå°è¯•2æ¬¡
GIT_RETRY_DELAY = 8 # é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
MAX_WORKERS = 15 # å¹¶å‘çº¿ç¨‹æ•°

# --- é•œåƒåŠ é€Ÿé…ç½® ---
USE_MIRROR = True # æ˜¯å¦å¯ç”¨é•œåƒåŠ é€Ÿ
# å¸¸ç”¨çš„GitHubé•œåƒæºåˆ—è¡¨ï¼ˆå¯æ ¹æ®éœ€è¦æ·»åŠ æˆ–ä¿®æ”¹ï¼‰
MIRROR_HOSTS = [
    "https://ghfast.top/",
    #"https://ghproxy.net/",
    #"https://wget.la/",
    "https://hk.gh-proxy.com/"
]
RANDOMIZE_MIRRORS = True # æ˜¯å¦éšæœºåŒ–é•œåƒæºé¡ºåºï¼Œå³ç®€å•çš„è´Ÿè½½å‡è¡¡

# --- å®‰å…¨é…ç½® ---
GIT_SECURITY_OPTS = ['-c', 'protocol.ext.allow=never', '-c', 'credential.helper=']

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def sanitize_filename(name: str) -> str:
    """å‡€åŒ–æ–‡ä»¶åï¼Œç§»é™¤Windowså’ŒLinuxä¸‹ä¸å…è®¸çš„å­—ç¬¦åŠæœ«å°¾çš„ç‚¹å’Œç©ºæ ¼ã€‚"""
    name = name.strip(' .')
    return re.sub(r'[<>:"/\\|?*]', '', name)

def run_command(command: list[str], cwd: Path | str, repo_name: str, retries: int = GIT_RETRIES, delay: int = GIT_RETRY_DELAY) -> bool:
    """ä¸ºå•ä¸ªå‘½ä»¤æ‰§è¡Œé‡è¯•é€»è¾‘ã€‚"""
    for attempt in range(retries):
        try:
            # å°†å®‰å…¨å‚æ•°æ’å…¥åˆ° 'git' å‘½ä»¤ä¹‹å
            git_index = command.index("git")
            final_command = command[:git_index+1] + GIT_SECURITY_OPTS + command[git_index+1:]
            
            subprocess.run(
                final_command, cwd=cwd, check=True, capture_output=True, text=True,
                encoding='utf-8', errors='ignore'
            )
            return True
        except (FileNotFoundError, ValueError):
            print(f"\n[!] 'git' å‘½ä»¤å¤„ç†é”™è¯¯ã€‚è¯·ç¡®ä¿ Git å·²å®‰è£…ã€‚")
            return False
        except subprocess.CalledProcessError as e:
            error_msg = e.stderr.strip()
            if attempt < retries - 1:
                print(f"\n[!] ä»“åº“ {repo_name} æ“ä½œå¤±è´¥ (å°è¯• {attempt + 1}/{retries})ã€‚å°†åœ¨ {delay} ç§’åé‡è¯•... é”™è¯¯: {error_msg}")
                time.sleep(delay)
            else:
                # åœ¨ä¸Šå±‚å‡½æ•°ä¸­æŠ¥å‘Šæœ€ç»ˆé”™è¯¯
                return False
    return False

def sync_meta_repo():
    """å…‹éš†æˆ–æ›´æ–°å…ƒæ•°æ®ä»“åº“ï¼Œä½¿ç”¨æ­£ç¡®çš„æ•…éšœåˆ‡æ¢é€»è¾‘ã€‚"""
    print(f"--- 1. åŒæ­¥å…ƒæ•°æ®ä»“åº“: {META_REPO_URL} ---")
    repo_name = "meta-repository"
    original_url = META_REPO_URL
    urls_to_try = [original_url]
    if USE_MIRROR:
        mirrors = MIRROR_HOSTS[:]
        if RANDOMIZE_MIRRORS: random.shuffle(mirrors)
        urls_to_try = [host + original_url for host in mirrors] + [original_url]

    # æ›´æ–°é€»è¾‘
    if META_REPO_PATH.is_dir() and META_REPO_PATH.joinpath(".git").is_dir():
        print(f"[*] å…ƒæ•°æ®ä»“åº“å·²å­˜åœ¨ï¼Œæ­£åœ¨æ‹‰å–æ›´æ–°...")
        update_successful = False
        try:
            for i, url in enumerate(urls_to_try):
                print(f"\r[*] å°è¯•æ›´æ–°å…ƒæ•°æ®ä»“åº“ (æº {i+1}/{len(urls_to_try)})...", end="")
                if run_command(["git", "remote", "set-url", "origin", url], META_REPO_PATH, repo_name, retries=1):
                    if run_command(["git", "pull"], META_REPO_PATH, repo_name):
                        update_successful = True
                        break
        finally:
            if USE_MIRROR:
                run_command(["git", "remote", "set-url", "origin", original_url], META_REPO_PATH, repo_name, retries=1)
        if not update_successful:
             print(f"\n[!] è­¦å‘Š: æ›´æ–°å…ƒæ•°æ®ä»“åº“å¤±è´¥ã€‚")
    # å…‹éš†é€»è¾‘
    else:
        print(f"[*] æ­£åœ¨å…‹éš†å…ƒæ•°æ®ä»“åº“...")
        clone_successful = False
        for i, url in enumerate(urls_to_try):
             print(f"\r[*] å°è¯•å…‹éš†å…ƒæ•°æ®ä»“åº“ (æº {i+1}/{len(urls_to_try)})...", end="")
             if run_command(["git", "clone", url, str(META_REPO_PATH)], ".", repo_name):
                 clone_successful = True
                 break
        if clone_successful and USE_MIRROR:
            run_command(["git", "remote", "set-url", "origin", original_url], META_REPO_PATH, repo_name, retries=1)
        elif not clone_successful:
             print(f"\n[!] é”™è¯¯: å…‹éš†å…ƒæ•°æ®ä»“åº“å¤±è´¥ï¼")
             exit(1)

    print(f"\n[*] å…ƒæ•°æ®ä»“åº“åŒæ­¥å®Œæˆã€‚\n")


def collect_poc_data_from_local() -> dict:
    # ... (æ­¤å‡½æ•°æ— éœ€ä¿®æ”¹)
    print("--- 2. ä»æœ¬åœ°æ‰«æå’Œæ”¶é›† CVE æ•°æ® ---")
    cve_data = defaultdict(list)
    total_json, valid_poc = 0, 0
    for root, _, files in os.walk(META_REPO_PATH):
        for file in files:
            if not file.endswith(".json"): continue
            total_json += 1
            file_path = Path(root) / file
            cve_id = file_path.stem
            try:
                with open(file_path, 'r', encoding='utf-8') as f: entries = json.load(f)
                if isinstance(entries, list):
                    for entry in entries:
                        if isinstance(entry, dict) and entry.get("html_url"):
                            if not entry['html_url'].endswith('.git'): entry['html_url'] += '.git'
                            entry['cve_id'] = cve_id
                            cve_data[cve_id].append(entry)
                            valid_poc += 1
            except json.JSONDecodeError: continue
    print(f"[*] æ‰«ææ€»ç»“: å…±æ£€æŸ¥ {total_json} ä¸ª.jsonæ–‡ä»¶, åŠ è½½äº† {valid_poc} ä¸ªPoCæ¡ç›® ({len(cve_data)}ä¸ªCVE)ã€‚\n")
    return cve_data

def sync_poc_repository(repo_url: str, local_path: Path) -> str:
    """å¥å£®åœ°åŒæ­¥å•ä¸ªPoCä»“åº“ï¼Œä½¿ç”¨æ­£ç¡®çš„é•œåƒåˆ‡æ¢å’Œå¼ºåˆ¶æ›´æ–°ã€‚"""
    repo_name = local_path.name
    original_url = repo_url
    urls_to_try = [original_url]
    if USE_MIRROR:
        mirrors = MIRROR_HOSTS[:]
        if RANDOMIZE_MIRRORS: random.shuffle(mirrors)
        urls_to_try = [host + original_url for host in mirrors] + [original_url]

    # é˜¶æ®µ1: å¦‚æœæ˜¯æœ‰æ•ˆä»“åº“ï¼Œå°è¯•å¼ºåˆ¶æ›´æ–°
    if local_path.is_dir() and local_path.joinpath(".git").is_dir():
        update_successful = False
        try:
            for i, url in enumerate(urls_to_try):
                if not run_command(["git", "remote", "set-url", "origin", url], local_path, repo_name, retries=1):
                    continue # è®¾ç½®è¿œç¨‹åœ°å€å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªé•œåƒ
                
                update_commands = [
                    ["git", "fetch", "--all", "--prune"],
                    ["git", "reset", "--hard", "origin/HEAD"],
                    ["git", "clean", "-fdx"]
                ]
                if all(run_command(cmd, local_path, repo_name, retries=1) for cmd in update_commands):
                    update_successful = True
                    break # æ›´æ–°æˆåŠŸï¼Œè·³å‡ºå¾ªç¯
        finally:
            if USE_MIRROR: # æ— è®ºç»“æœå¦‚ä½•ï¼Œéƒ½æ¢å¤åŸå§‹URL
                run_command(["git", "remote", "set-url", "origin", original_url], local_path, repo_name, retries=1)
        
        if update_successful:
            return repo_url

        print(f"\n[!] ä»“åº“ {repo_name} å¼ºåˆ¶æ›´æ–°å¤±è´¥ï¼Œå°†æ‰§è¡Œåˆ é™¤åé‡æ–°å…‹éš†ç­–ç•¥ã€‚")
    
    # é˜¶æ®µ2: å¦‚æœä¸æ˜¯æœ‰æ•ˆä»“åº“ï¼Œæˆ–æ›´æ–°å¤±è´¥ï¼Œåˆ™æ‰§è¡Œâ€œåˆ äº†é‡æ¥â€ç­–ç•¥
    if local_path.exists():
        try:
            shutil.rmtree(local_path)
        except OSError as e:
            print(f"\n[!] æ¸…ç†ç›®å½• {local_path} å¤±è´¥: {e}ã€‚è·³è¿‡æ­¤ä»“åº“ã€‚")
            return repo_url

    clone_successful = False
    for i, url in enumerate(urls_to_try):
        if run_command(["git", "clone", "--depth", "1", url, str(local_path)], ".", repo_name):
            clone_successful = True
            break
            
    if clone_successful and USE_MIRROR:
        run_command(["git", "remote", "set-url", "origin", original_url], local_path, repo_name, retries=1)
    elif not clone_successful:
        print(f"\n[!] ä»“åº“ {repo_name} å…‹éš†å¤±è´¥ï¼šå·²å°è¯•æ‰€æœ‰é•œåƒæºåŠå®˜æ–¹æºã€‚")
            
    return repo_url


def generate_summary_files(cve_id: str, entries: list, cve_dir: Path):
    # ... (æ­¤å‡½æ•°æ— éœ€ä¿®æ”¹)
    cve_dir.mkdir(parents=True, exist_ok=True)
    with open(cve_dir / "metadata.json", 'w', encoding='utf-8') as f:
        json.dump(entries, f, indent=4, ensure_ascii=False)
    
    main_desc = "No description available."
    if entries:
        first_entry = entries[0]
        main_desc = (first_entry.get('summary') or first_entry.get('repo_description') 
                     or first_entry.get('description', main_desc)).replace('\n', ' ').strip()

    readme_content = f"# {cve_id}\n\n**æ¼æ´æè¿°:** {main_desc}\n\n---\n\n## ç›¸å…³ PoC ä»“åº“ ({len(entries)} ä¸ª)\n\n"
    for i, entry in enumerate(entries, 1):
        display_url = entry.get('html_url', '#').removesuffix('.git')
        readme_content += (
            f"### {i}. [{entry.get('full_name', 'N/A')}]({display_url})\n\n"
            f"- **ä»“åº“æè¿°:** {entry.get('description') or 'ä½œè€…æœªæä¾›ä»“åº“æè¿°ã€‚'}\n"
            f"- **Stars:** â­ {entry.get('stargazers_count', 0)}\n"
            f"- **Forks:** ğŸ´ {entry.get('forks_count', 0)}\n"
            f"- **æœ€åæ›´æ–°:** {entry.get('pushed_at', 'N/A').split('T')[0]}\n\n"
        )
    with open(cve_dir / "README.md", 'w', encoding='utf-8') as f:
        f.write(readme_content)

def main():
    """è„šæœ¬ä¸»å…¥å£ã€‚"""
    print(f"--- PoC-in-GitHub æœ¬åœ°çŸ¥è¯†åº“åŒæ­¥å·¥å…· (V9 - ç»ˆæå¥å£®ç‰ˆ) ---")
    if USE_MIRROR:
        print(f"[*] é•œåƒåŠ é€ŸåŠŸèƒ½: å·²å¯ç”¨ ({len(MIRROR_HOSTS)}ä¸ªé•œåƒæº, {'éšæœºé¡ºåº' if RANDOMIZE_MIRRORS else 'å›ºå®šé¡ºåº'})")
    else:
        print(f"[*] é•œåƒåŠ é€ŸåŠŸèƒ½: å·²ç¦ç”¨")
    print(f"[*] å®‰å…¨å¢å¼º: å·²å¯ç”¨ (ç¦ç”¨å¤–éƒ¨åè®®å’Œå‡­æ®åŠ©æ‰‹)")
    
    sync_meta_repo()
    all_cve_data = collect_poc_data_from_local()

    if not all_cve_data:
        print("[!] æœªæ”¶é›†åˆ°ä»»ä½•æœ‰æ•ˆçš„ CVE æ•°æ®ï¼Œä»»åŠ¡æå‰ç»“æŸã€‚")
        return

    print("--- 3. æ”¶é›†æ‰€æœ‰éœ€è¦åŒæ­¥çš„ä»“åº“ä»»åŠ¡ ---")
    tasks = []
    for cve_id, entries in all_cve_data.items():
        try:
            year = cve_id.split('-')[1]
            cve_dir = LOCAL_POC_DIR / year / cve_id
            generate_summary_files(cve_id, entries, cve_dir)
            for entry in entries:
                repo_owner, repo_name = entry.get("full_name").split('/')
                safe_repo_name = sanitize_filename(f"{repo_owner}_{repo_name}")
                repo_path = cve_dir / "repositories" / safe_repo_name
                tasks.append((entry.get("html_url"), repo_path))
        except (AttributeError, IndexError, KeyError, TypeError):
            continue
    print(f"[*] å…±æ”¶é›†åˆ° {len(tasks)} ä¸ªä»“åº“åŒæ­¥ä»»åŠ¡ã€‚\n")

    print(f"--- 4. ä½¿ç”¨ {MAX_WORKERS} ä¸ªçº¿ç¨‹å¹¶å‘åŒæ­¥ä»“åº“ ---")
    if tasks:
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_task = {executor.submit(sync_poc_repository, url, path): url for url, path in tasks}
            for i, future in enumerate(as_completed(future_to_task), 1):
                url = future.result().removesuffix('.git')
                print(f"\r[*] åŒæ­¥è¿›åº¦: {i}/{len(tasks)} ({Path(url).name})\x1b[K", end='')
    
    print(f"\n[*] æ‰€æœ‰ä»“åº“åŒæ­¥å®Œæˆã€‚\n")
    print("--- âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ ---")

if __name__ == "__main__":
    main()